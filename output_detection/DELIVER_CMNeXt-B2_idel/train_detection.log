20250512 03:22:12 - root - INFO: - Saving results to output_detection/DELIVER_CMNeXt-B2_idel
20250512 03:22:13 - root - INFO: - Attempting to load pretrained weights for backbone from: checkpoints/pretrained/segformer/mit_b2.pth
20250512 03:22:15 - root - INFO: - ================== model structure =====================
20250512 03:22:15 - root - INFO: - CMNeXtFasterRCNN(
  (transform): GeneralizedRCNNTransform(
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
      Resize(min_size=(800,), max_size=1333, mode='bilinear')
  )
  (backbone): BackboneWithCustomFPN(
    (body): CMNeXtBackbone(
      (backbone): CMNeXt(
        (patch_embed1): PatchEmbed(
          (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (patch_embed2): PatchEmbed(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (patch_embed3): PatchEmbed(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (patch_embed4): PatchEmbed(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (extra_downsample_layers): ModuleList(
          (0): PatchEmbedParallel(
            (proj): ModuleParallel(
              (module): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
            )
            (norm): LayerNormParallel(
              (ln_0): ConvLayerNorm()
              (ln_1): ConvLayerNorm()
              (ln_2): ConvLayerNorm()
            )
          )
          (1): PatchEmbedParallel(
            (proj): ModuleParallel(
              (module): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
            (norm): LayerNormParallel(
              (ln_0): ConvLayerNorm()
              (ln_1): ConvLayerNorm()
              (ln_2): ConvLayerNorm()
            )
          )
          (2): PatchEmbedParallel(
            (proj): ModuleParallel(
              (module): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
            (norm): LayerNormParallel(
              (ln_0): ConvLayerNorm()
              (ln_1): ConvLayerNorm()
              (ln_2): ConvLayerNorm()
            )
          )
          (3): PatchEmbedParallel(
            (proj): ModuleParallel(
              (module): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            )
            (norm): LayerNormParallel(
              (ln_0): ConvLayerNorm()
              (ln_1): ConvLayerNorm()
              (ln_2): ConvLayerNorm()
            )
          )
        )
        (extra_score_predictor): ModuleList(
          (0): PredictorConv(
            (score_nets): ModuleList(
              (0): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
                (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
              (1): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
                (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
              (2): Sequential(
                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
                (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
            )
          )
          (1): PredictorConv(
            (score_nets): ModuleList(
              (0): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
              (1): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
              (2): Sequential(
                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
            )
          )
          (2): PredictorConv(
            (score_nets): ModuleList(
              (0): Sequential(
                (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
                (1): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
              (1): Sequential(
                (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
                (1): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
              (2): Sequential(
                (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
                (1): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
            )
          )
          (3): PredictorConv(
            (score_nets): ModuleList(
              (0): Sequential(
                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
              (1): Sequential(
                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
              (2): Sequential(
                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
                (2): Sigmoid()
              )
            )
          )
        )
        (block1): ModuleList(
          (0): Block(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=64, out_features=64, bias=True)
              (kv): Linear(in_features=64, out_features=128, bias=True)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (fc2): Linear(in_features=256, out_features=64, bias=True)
            )
          )
          (1): Block(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=64, out_features=64, bias=True)
              (kv): Linear(in_features=64, out_features=128, bias=True)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (fc2): Linear(in_features=256, out_features=64, bias=True)
            )
          )
          (2): Block(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=64, out_features=64, bias=True)
              (kv): Linear(in_features=64, out_features=128, bias=True)
              (proj): Linear(in_features=64, out_features=64, bias=True)
              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (fc2): Linear(in_features=256, out_features=64, bias=True)
            )
          )
        )
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (extra_block1): ModuleList(
          (0): MSPABlock(
            (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): Identity()
            (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (1): MSPABlock(
            (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (2): MSPABlock(
            (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
        )
        (extra_norm1): ConvLayerNorm()
        (block2): ModuleList(
          (0): Block(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (fc2): Linear(in_features=512, out_features=128, bias=True)
            )
          )
          (1): Block(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (fc2): Linear(in_features=512, out_features=128, bias=True)
            )
          )
          (2): Block(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (fc2): Linear(in_features=512, out_features=128, bias=True)
            )
          )
          (3): Block(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=128, out_features=128, bias=True)
              (kv): Linear(in_features=128, out_features=256, bias=True)
              (proj): Linear(in_features=128, out_features=128, bias=True)
              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (fc2): Linear(in_features=512, out_features=128, bias=True)
            )
          )
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (extra_block2): ModuleList(
          (0): MSPABlock(
            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (1): MSPABlock(
            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (2): MSPABlock(
            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (3): MSPABlock(
            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
        )
        (extra_norm2): ConvLayerNorm()
        (block3): ModuleList(
          (0): Block(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
            )
          )
          (1): Block(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
            )
          )
          (2): Block(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
            )
          )
          (3): Block(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
            )
          )
          (4): Block(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
            )
          )
          (5): Block(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=320, out_features=320, bias=True)
              (kv): Linear(in_features=320, out_features=640, bias=True)
              (proj): Linear(in_features=320, out_features=320, bias=True)
              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
            )
          )
        )
        (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (extra_block3): ModuleList(
          (0): MSPABlock(
            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (1): MSPABlock(
            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (2): MSPABlock(
            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (3): MSPABlock(
            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (4): MSPABlock(
            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (5): MSPABlock(
            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(320, 320, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=320)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
        )
        (extra_norm3): ConvLayerNorm()
        (block4): ModuleList(
          (0): Block(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (proj): Linear(in_features=512, out_features=512, bias=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
            )
          )
          (1): Block(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (proj): Linear(in_features=512, out_features=512, bias=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
            )
          )
          (2): Block(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (proj): Linear(in_features=512, out_features=512, bias=True)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): MLP(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
            )
          )
        )
        (norm4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (extra_block4): ModuleList(
          (0): MSPABlock(
            (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (1): MSPABlock(
            (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
          (2): MSPABlock(
            (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (attn): MSPoolAttention(
              (conv0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
              (pool1): AvgPool2d(kernel_size=3, stride=1, padding=1)
              (pool2): AvgPool2d(kernel_size=7, stride=1, padding=3)
              (pool3): AvgPool2d(kernel_size=11, stride=1, padding=5)
              (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (sigmoid): Sigmoid()
            )
            (drop_path): DropPath()
            (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (mlp): Mlp(
              (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
              (dwconv): DWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
              (drop): Dropout(p=0.0, inplace=False)
            )
            (avg_pool): AdaptiveAvgPool2d(output_size=1)
            (c_nets): Sequential(
              (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): Sigmoid()
            )
          )
        )
        (extra_norm4): ConvLayerNorm()
        (FRMs): ModuleList(
          (0): FeatureRectifyModule(
            (channel_weights): ChannelWeights(
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (max_pool): AdaptiveMaxPool2d(output_size=1)
              (mlp): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=256, out_features=128, bias=True)
                (3): Sigmoid()
              )
            )
            (spatial_weights): SpatialWeights(
              (mlp): Sequential(
                (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): ReLU(inplace=True)
                (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
                (3): Sigmoid()
              )
            )
          )
          (1): FeatureRectifyModule(
            (channel_weights): ChannelWeights(
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (max_pool): AdaptiveMaxPool2d(output_size=1)
              (mlp): Sequential(
                (0): Linear(in_features=512, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=256, bias=True)
                (3): Sigmoid()
              )
            )
            (spatial_weights): SpatialWeights(
              (mlp): Sequential(
                (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
                (1): ReLU(inplace=True)
                (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))
                (3): Sigmoid()
              )
            )
          )
          (2): FeatureRectifyModule(
            (channel_weights): ChannelWeights(
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (max_pool): AdaptiveMaxPool2d(output_size=1)
              (mlp): Sequential(
                (0): Linear(in_features=1280, out_features=1280, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=1280, out_features=640, bias=True)
                (3): Sigmoid()
              )
            )
            (spatial_weights): SpatialWeights(
              (mlp): Sequential(
                (0): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
                (1): ReLU(inplace=True)
                (2): Conv2d(320, 2, kernel_size=(1, 1), stride=(1, 1))
                (3): Sigmoid()
              )
            )
          )
          (3): FeatureRectifyModule(
            (channel_weights): ChannelWeights(
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (max_pool): AdaptiveMaxPool2d(output_size=1)
              (mlp): Sequential(
                (0): Linear(in_features=2048, out_features=2048, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=2048, out_features=1024, bias=True)
                (3): Sigmoid()
              )
            )
            (spatial_weights): SpatialWeights(
              (mlp): Sequential(
                (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
                (1): ReLU(inplace=True)
                (2): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))
                (3): Sigmoid()
              )
            )
          )
        )
        (FFMs): ModuleList(
          (0): FeatureFusionModule(
            (cross): CrossPath(
              (channel_proj1): Linear(in_features=64, out_features=128, bias=True)
              (channel_proj2): Linear(in_features=64, out_features=128, bias=True)
              (act1): ReLU(inplace=True)
              (act2): ReLU(inplace=True)
              (cross_attn): CrossAttention(
                (kv1): Linear(in_features=64, out_features=128, bias=False)
                (kv2): Linear(in_features=64, out_features=128, bias=False)
              )
              (end_proj1): Linear(in_features=128, out_features=64, bias=True)
              (end_proj2): Linear(in_features=128, out_features=64, bias=True)
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            )
            (channel_emb): ChannelEmbed(
              (residual): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (channel_embed): Sequential(
                (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
                (2): ReLU(inplace=True)
                (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): FeatureFusionModule(
            (cross): CrossPath(
              (channel_proj1): Linear(in_features=128, out_features=256, bias=True)
              (channel_proj2): Linear(in_features=128, out_features=256, bias=True)
              (act1): ReLU(inplace=True)
              (act2): ReLU(inplace=True)
              (cross_attn): CrossAttention(
                (kv1): Linear(in_features=128, out_features=256, bias=False)
                (kv2): Linear(in_features=128, out_features=256, bias=False)
              )
              (end_proj1): Linear(in_features=256, out_features=128, bias=True)
              (end_proj2): Linear(in_features=256, out_features=128, bias=True)
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (channel_emb): ChannelEmbed(
              (residual): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (channel_embed): Sequential(
                (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
                (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
                (2): ReLU(inplace=True)
                (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): FeatureFusionModule(
            (cross): CrossPath(
              (channel_proj1): Linear(in_features=320, out_features=640, bias=True)
              (channel_proj2): Linear(in_features=320, out_features=640, bias=True)
              (act1): ReLU(inplace=True)
              (act2): ReLU(inplace=True)
              (cross_attn): CrossAttention(
                (kv1): Linear(in_features=320, out_features=640, bias=False)
                (kv2): Linear(in_features=320, out_features=640, bias=False)
              )
              (end_proj1): Linear(in_features=640, out_features=320, bias=True)
              (end_proj2): Linear(in_features=640, out_features=320, bias=True)
              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            )
            (channel_emb): ChannelEmbed(
              (residual): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (channel_embed): Sequential(
                (0): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
                (1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)
                (2): ReLU(inplace=True)
                (3): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
                (4): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (3): FeatureFusionModule(
            (cross): CrossPath(
              (channel_proj1): Linear(in_features=512, out_features=1024, bias=True)
              (channel_proj2): Linear(in_features=512, out_features=1024, bias=True)
              (act1): ReLU(inplace=True)
              (act2): ReLU(inplace=True)
              (cross_attn): CrossAttention(
                (kv1): Linear(in_features=512, out_features=1024, bias=False)
                (kv2): Linear(in_features=512, out_features=1024, bias=False)
              )
              (end_proj1): Linear(in_features=1024, out_features=512, bias=True)
              (end_proj2): Linear(in_features=1024, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (channel_emb): ChannelEmbed(
              (residual): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (channel_embed): Sequential(
                (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (2): ReLU(inplace=True)
                (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
                (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
      )
    )
    (fpn_projections): ModuleDict(
      (0): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(320, 512, kernel_size=(1, 1), stride=(1, 1))
      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (rpn): RegionProposalNetwork(
    (anchor_generator): AnchorGenerator()
    (head): RPNHead(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
        )
      )
      (cls_logits): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))
      (bbox_pred): Conv2d(512, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): RoIHeads(
    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)
    (box_head): TwoMLPHead(
      (fc6): Linear(in_features=25088, out_features=1024, bias=True)
      (fc7): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNPredictor(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)
    )
  )
)
20250512 03:22:15 - root - INFO: - ================== training config =====================
20250512 03:22:15 - root - INFO: - {'DEVICE': 'cuda', 'SAVE_DIR': 'output', 'MODEL': {'NAME': 'CMNeXt', 'BACKBONE': 'CMNeXt-B2', 'PRETRAINED': 'checkpoints/pretrained/segformer/mit_b2.pth', 'RESUME': ''}, 'DATASET': {'NAME': 'DELIVER', 'ROOT': 'data/DELIVER', 'IGNORE_LABEL': 255, 'MODALS': ['image', 'depth', 'event', 'lidar']}, 'TRAIN': {'IMAGE_SIZE': [512, 512], 'BATCH_SIZE': 2, 'EPOCHS': 200, 'EVAL_START': 100, 'EVAL_INTERVAL': 1, 'AMP': False, 'DDP': False}, 'LOSS': {'NAME': 'OhemCrossEntropy', 'CLS_WEIGHTS': False}, 'OPTIMIZER': {'NAME': 'adamw', 'LR': 6e-05, 'WEIGHT_DECAY': 0.01}, 'SCHEDULER': {'NAME': 'warmuppolylr', 'POWER': 0.9, 'WARMUP': 10, 'WARMUP_RATIO': 0.1}, 'EVAL': {'MODEL_PATH': 'output/DELIVER/cmnext_b2_deliver_rgbdel.pth', 'IMAGE_SIZE': [512, 512], 'BATCH_SIZE': 1, 'MSF': {'ENABLE': False, 'FLIP': True, 'SCALES': [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]}}, 'TEST': {'MODEL_PATH': 'output/DELIVER/cmnext_b2_deliver_rgbdel.pth', 'FILE': 'data/DELIVER', 'IMAGE_SIZE': [512, 512], 'OVERLAY': True}}
